{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Loading and Preprocessing:\n",
    "\n",
    "1. Load images from dataset.\n",
    "2. Preprocess images by resizing, normalizing, and handling imbalanced data to improve model performance and generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -----------\n",
      "absl-py                      1.4.0\n",
      "anyio                        3.7.1\n",
      "argon2-cffi                  21.3.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "arrow                        1.2.3\n",
      "asttokens                    2.2.1\n",
      "astunparse                   1.6.3\n",
      "async-lru                    2.0.4\n",
      "attrs                        23.1.0\n",
      "Babel                        2.12.1\n",
      "backcall                     0.2.0\n",
      "beautifulsoup4               4.12.2\n",
      "bleach                       6.0.0\n",
      "cachetools                   5.3.1\n",
      "certifi                      2023.7.22\n",
      "cffi                         1.15.1\n",
      "charset-normalizer           3.2.0\n",
      "colorama                     0.4.6\n",
      "comm                         0.1.4\n",
      "contourpy                    1.1.0\n",
      "cycler                       0.11.0\n",
      "debugpy                      1.6.7.post1\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "executing                    1.2.0\n",
      "fastjsonschema               2.18.0\n",
      "flatbuffers                  23.5.26\n",
      "fonttools                    4.42.0\n",
      "fqdn                         1.5.1\n",
      "gast                         0.4.0\n",
      "google-auth                  2.22.0\n",
      "google-auth-oauthlib         1.0.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.56.2\n",
      "h5py                         3.9.0\n",
      "idna                         3.4\n",
      "ipykernel                    6.25.1\n",
      "ipython                      8.14.0\n",
      "ipython-genutils             0.2.0\n",
      "ipywidgets                   8.1.0\n",
      "isoduration                  20.11.0\n",
      "jedi                         0.19.0\n",
      "Jinja2                       3.1.2\n",
      "json5                        0.9.14\n",
      "jsonpointer                  2.4\n",
      "jsonschema                   4.19.0\n",
      "jsonschema-specifications    2023.7.1\n",
      "jupyter                      1.0.0\n",
      "jupyter_client               8.3.0\n",
      "jupyter-console              6.6.3\n",
      "jupyter_core                 5.3.1\n",
      "jupyter-events               0.7.0\n",
      "jupyter-lsp                  2.2.0\n",
      "jupyter_server               2.7.0\n",
      "jupyter_server_terminals     0.4.4\n",
      "jupyterlab                   4.0.4\n",
      "jupyterlab-pygments          0.2.2\n",
      "jupyterlab_server            2.24.0\n",
      "jupyterlab-widgets           3.0.8\n",
      "keras                        2.13.1\n",
      "kiwisolver                   1.4.4\n",
      "libclang                     16.0.6\n",
      "Markdown                     3.4.4\n",
      "MarkupSafe                   2.1.3\n",
      "matplotlib                   3.7.2\n",
      "matplotlib-inline            0.1.6\n",
      "mistune                      3.0.1\n",
      "nbclient                     0.8.0\n",
      "nbconvert                    7.7.3\n",
      "nbformat                     5.9.2\n",
      "nest-asyncio                 1.5.7\n",
      "notebook                     7.0.2\n",
      "notebook_shim                0.2.3\n",
      "numpy                        1.24.3\n",
      "oauthlib                     3.2.2\n",
      "opencv-python                4.8.0.76\n",
      "opt-einsum                   3.3.0\n",
      "overrides                    7.4.0\n",
      "packaging                    23.1\n",
      "pandocfilters                1.5.0\n",
      "parso                        0.8.3\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       10.0.0\n",
      "pip                          23.2.1\n",
      "platformdirs                 3.10.0\n",
      "prometheus-client            0.17.1\n",
      "prompt-toolkit               3.0.39\n",
      "protobuf                     4.24.0\n",
      "psutil                       5.9.5\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.5.0\n",
      "pyasn1-modules               0.3.0\n",
      "pycparser                    2.21\n",
      "Pygments                     2.16.1\n",
      "pyparsing                    3.0.9\n",
      "python-dateutil              2.8.2\n",
      "python-json-logger           2.0.7\n",
      "pywin32                      306\n",
      "pywinpty                     2.0.11\n",
      "PyYAML                       6.0.1\n",
      "pyzmq                        25.1.1\n",
      "qtconsole                    5.4.3\n",
      "QtPy                         2.3.1\n",
      "referencing                  0.30.2\n",
      "requests                     2.31.0\n",
      "requests-oauthlib            1.3.1\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rpds-py                      0.9.2\n",
      "rsa                          4.9\n",
      "scipy                        1.11.1\n",
      "Send2Trash                   1.8.2\n",
      "setuptools                   65.5.0\n",
      "six                          1.16.0\n",
      "sniffio                      1.3.0\n",
      "soupsieve                    2.4.1\n",
      "stack-data                   0.6.2\n",
      "tensorboard                  2.13.0\n",
      "tensorboard-data-server      0.7.1\n",
      "tensorflow                   2.13.0\n",
      "tensorflow-estimator         2.13.0\n",
      "tensorflow-intel             2.13.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.3.0\n",
      "terminado                    0.17.1\n",
      "tinycss2                     1.2.1\n",
      "tornado                      6.3.2\n",
      "traitlets                    5.9.0\n",
      "typing_extensions            4.5.0\n",
      "uri-template                 1.3.0\n",
      "urllib3                      1.26.16\n",
      "wcwidth                      0.2.6\n",
      "webcolors                    1.13\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.6.1\n",
      "Werkzeug                     2.3.6\n",
      "wheel                        0.41.1\n",
      "widgetsnbextension           4.0.8\n",
      "wrapt                        1.15.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install scipy\n",
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.executable\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ASUS\\\\OneDrive - Singapore Management University\\\\Documents\\\\GitHub\\\\Fresh-to-Death-Data-Science-Project\\\\venv\\\\Scripts\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\\test\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3115 files belonging to 36 classes.\n",
      "Found 351 files belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "val_path=\"data/validation\"\n",
    "train_path=\"data/train\"\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    seed=2509,\n",
    "    image_size=(224, 224), # Resize\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_path,\n",
    "    seed=2509,\n",
    "    image_size=(224, 224), # Resize\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class apple: 68 images\n",
      "Class banana: 75 images\n",
      "Class beetroot: 88 images\n",
      "Class bell pepper: 90 images\n",
      "Class cabbage: 92 images\n",
      "Class capsicum: 89 images\n",
      "Class carrot: 82 images\n",
      "Class cauliflower: 79 images\n",
      "Class chilli pepper: 87 images\n",
      "Class corn: 87 images\n",
      "Class cucumber: 94 images\n",
      "Class eggplant: 84 images\n",
      "Class garlic: 92 images\n",
      "Class ginger: 68 images\n",
      "Class grapes: 100 images\n",
      "Class jalepeno: 88 images\n",
      "Class kiwi: 88 images\n",
      "Class lemon: 82 images\n",
      "Class lettuce: 97 images\n",
      "Class mango: 86 images\n",
      "Class onion: 94 images\n",
      "Class orange: 69 images\n",
      "Class paprika: 83 images\n",
      "Class pear: 89 images\n",
      "Class peas: 100 images\n",
      "Class pineapple: 99 images\n",
      "Class pomegranate: 79 images\n",
      "Class potato: 77 images\n",
      "Class raddish: 81 images\n",
      "Class soy beans: 97 images\n",
      "Class spinach: 97 images\n",
      "Class sweetcorn: 91 images\n",
      "Class sweetpotato: 69 images\n",
      "Class tomato: 92 images\n",
      "Class turnip: 98 images\n",
      "Class watermelon: 84 images\n"
     ]
    }
   ],
   "source": [
    "# Define the class names based on the subdirectories in the training directory\n",
    "class_names = sorted(os.listdir(train_path))\n",
    "\n",
    "# Initialize label counts\n",
    "label_counts = {class_name: 0 for class_name in class_names}\n",
    "\n",
    "# Count the images per class\n",
    "for images, labels in train_dataset:\n",
    "    for label in labels.numpy():\n",
    "        class_name = class_names[label]\n",
    "        label_counts[class_name] += 1\n",
    "\n",
    "# Print the class names and label counts\n",
    "for class_name, count in label_counts.items():\n",
    "    print(\"Class {}: {} images\".format(class_name, count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Apply augmentation to the normalized dataset\n",
    "augmented_data = []\n",
    "\n",
    "for images, labels in train_dataset:\n",
    "    augmented_images = augmentation_generator.flow(images, batch_size=images.shape[0])\n",
    "    for augmented_image_batch in augmented_images:\n",
    "        augmented_data.append((augmented_image_batch, labels))\n",
    "\n",
    "# Combine original and augmented data\n",
    "combined_data = train_dataset.concatenate(tf.data.Dataset.from_generator(\n",
    "    lambda: ((x, y) for x, y in augmented_data), \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "    )\n",
    "))\n",
    "\n",
    "# Shuffle the combined data\n",
    "combined_data = combined_data.shuffle(buffer_size=len(combined_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize pixel values using the map() function\n",
    "train_Normalize = combined_data.map(lambda x, y: (x / 255, y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (x / 255, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the YOLO (You Only Look Once) model to your normalized and balanced data\n",
    "\n",
    "1. Load images from dataset.\n",
    "2. Preprocess images by resizing, normalizing, and handling imbalanced data to improve model performance and generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
